# HK-O1aw

[包括模型介绍，参数，预期的场景@Sirui Han，讲一讲背景]
6 ~ 7 行

## Examples


<table>
    <thead>
        <tr>
            <th>Model Case</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><details><summary>Case 1</summary>

**Prompt:**<br>
一般来说，医生是否可以在未取得病人同意的情况下为病人施予治疗或展开医疗程序?<br>

**Output:**<br>
**分析法律背景**<br>
根据香港的法律，医生通常需要病人的同意才能进行治疗或医疗程序。然而，有例外情况允许在紧急情况下不经同意即可进行治疗，以拯救病人的生命。<br>

**理解紧急情况的例外**<br>
在紧急情况下，如果病人无法给予同意且延误治疗可能危及生命，医生可以在未取得同意的情况下采取行动。这是为了确保病人的生命安全。<br>

**考虑其他可能性**<br>
除了紧急情况，医生通常需要病人或其家属的同意才能进行治疗。没有其他明确的法律条款允许在非紧急情况下不经同意进行治疗。

通过分析，我们确认在非紧急情况下，医生通常需要病人或其家属的同意才能进行治疗。只有在紧急情况下，为了拯救生命而无需获得同意。
</details>     </td>
        </tr>
        <tr>
            <td><details><summary>Case 2</summary>

**Prompt**<br>
业主和租客在没有书面租约下出租和租用物业会涉及甚么潜在的风险？<br>

**Output:**<br>
**分析没有书面租约的风险** 
<br>在没有书面租约的情况下，业主和租客可能面临多种风险。首先，双方可能对租赁条款产生分歧，导致法律纠纷。其次，缺乏书面记录可能使得租客在物业管理或维修问题上处于不利地位。此外，如果物业被没收或政府收回土地，租客可能无法获得任何补偿。

**方法一：法律纠纷的可能性**  
如果没有书面协议，双方在出租和使用细节上可能会有不同的理解。这种情况下，如果发生争议，法律上很难证明谁是谁非。这意味着如果一方认为另一方违反了协议，他们可能无法通过法律途径获得补偿或解决。

**方法二：物业管理和维修问题**  
在没有书面协议的情况下，租客通常无法证明他们支付了费用，因此很难要求业主进行必要的维修或管理。这也意味着如果有任何损坏或需要维护的问题，双方之间的沟通和协调变得更加复杂。

**方法三：政府收回土地的风险**  
如果物业被政府没收或收回土地，没有书面协议将使得租客无法获得任何补偿。因为法律上没有明确的合同条款来支持他们的地位，他们可能会失去已付出的所有投资。

通过不同的角度分析，我们可以确认没有书面协议存在多种潜在风险。这些包括法律纠纷、物业管理问题以及政府收回土地的风险。每种方法都从不同方面验证了这些风险，并且都指向相同的结论，即缺乏书面记录会导致严重后果。
</details>  </td>
        </tr>
        <tr>
            <td><details><summary>Case 3</summary>

**Prompt:** <br>
我很少参与高危运动（例如滑水），但我有一次玩这类运动时受伤。这次受伤会被视为「意外」、「自招」抑或「疏忽」事件呢？它会否影响我的医疗或意外保险索偿？

**Output:**<br>
**分析受伤事件的性质**  
首先，我们需要确定受伤事件的性质。根据定义，意外是指非故意、不可预见和非惯常的事件。自招是指因过度自信或疏忽导致的事故，而疏忽则是指未能采取合理谨慎措施。

**评估滑水作为高危运动**  
滑水被归类为高危运动，这意味着它本身具有较高的风险性。我们需要考虑在这种情况下，受伤是否符合意外的定义，即不可预见和非故意。

**检查保险条款中的例外情况**  
保险合同通常会列出某些例外情况，例如参与高危运动时发生的事故可能不被涵盖。这需要仔细检查保险合同中的具体条款。

**考虑医疗和意外保险索偿影响**  
如果受伤被视为意外而非自招或疏忽，通常会影响保险索偿。医疗保险可能涵盖部分费用，而意外保险则可能提供更全面的赔偿。

通过多种方法分析，我们可以得出结论：如果受伤事件符合意外的定义，并且不在保险合同中的例外情况内，则可能不会影响索偿。但如果被视为自招或疏忽，则可能会影响索偿。
</details>  </td>
        </tr>
        <tr>
            <td><details><summary>Case 4</summary>

**Prompt:** <br>
草拟一份优秀的状书的基本原则是甚么？

**Output:**<br>
**分析状书的基本要求**  
状书是法律程序中的重要文件，用于正式提出法律请求或申索。其目的是清楚地陈述申索的基础和相关事实。因此，草拟状书时需要明确、具体和准确地描述事件的经过。

**方法一：从法律程序角度分析**  
从法律程序的角度来看，状书必须遵循特定的格式和内容要求。这包括提供详细的事实支持、明确列出申索理由以及提供相关证据的概要。这种方法强调对法律程序的遵循。

**方法二：从沟通效率角度分析**  
从沟通效率的角度来看，状书应清晰易读，以便法庭和各方能够迅速理解案件背景和申索内容。这意味着使用简单明了的语言，并分段组织信息，以便快速查阅。

**方法三：从策略性角度分析**  
从策略性角度来看，草拟者应考虑如何最有效地支持自己的立场。通过选择合适的事实和证据，可以最大化影响法庭判决。此外，了解对方可能提出的抗辩，并在状书中准备相应回应。

通过多种方法验证后，最终确认优秀状书需具备清晰、准确、全面、易读及策略性的特征。这些特征共同确保法庭能够有效理解案件背景并作出公正判决。
</details>  </td>
        </tr>
        <tr>
            <td><details><summary>Case 5</summary>

**Prompt:** <br>
商业为什么需要调解和仲裁？

**Output:** <br>
**分析商业调解的必要性**  
商业调解在国际贸易中起着重要作用，因为它提供了一种非对抗性的解决争议的方式。通过调解，双方可以在保密的环境下讨论问题，避免公开的法律程序，这对于维护商业关系至关重要。

**探讨仲裁的优势**  
仲裁是一种更正式的纠纷解决方式，通常比法院诉讼更快、更私密，并且仲裁判决具有法律约束力。由于国际贸易中可能涉及不同司法管辖区，仲裁提供了一个统一的法律框架来解决争议。

**比较调解和仲裁**  
调解和仲裁都是替代性争议解决机制，但它们有不同的特点。调解是自愿且灵活的，而仲裁则具有法律约束力。商业需要这两种机制，以满足不同的需求：调解用于快速解决小额纠纷，而仲裁用于复杂或高价值交易。

**验证和排除其他可能性**  
考虑到其他可能的争议解决方式，如直接协商或诉讼，发现这些方法各有局限性。直接协商可能不具备强制执行力，而诉讼过程复杂且耗时。此外，国际贸易中的不同法律体系使得法院诉讼变得复杂。

通过重新审视各个步骤，确认调解和仲裁在国际贸易中的独特作用。它们提供了灵活性、保密性和法律保障，使得商业能够有效地管理风险并维护关系。
</details>  </td>
        </tr>
    </tbody>
</table>

# Dataset Overview

O1aw-Dataset is a comprehensive legal question-thought-answer dataset, designed to evaluate and enhance legal reasoning capabilities in language models. The dataset follows the O1-style format, featuring complex legal scenarios that require multi-step reasoning.

## Our training dataset
How was our dataset constructed? First, we crawled and cleaned raw legal materials from the internet, including [Hong Kong e-Legislation](https://www.elegislation.gov.hk). Then, we used GPT-4o to generate corresponding questions and thought-answer pairs based on the raw legal materials.

The dataset contains 15,959 question-thought-answer triples, each equipped with complete chain-of-thought annotations. All content is presented in Simplified Chinese and stored in a structured JSON format. The difficulty level of the questions in this dataset is intermediate to advanced for legal professionals and law school students.

The question types cover case analysis, legal application, explanation of legal concepts and so on. Each QTA triple includes detailed question prompt, a 3-5 step chain-of-thought reasoning process, and answer. The reasoning process involves multi-stage validation, reflective verification steps, and cross-case consistency checks, ensuring diversity in reasoning.

### Prompts for QTA generation
Here is our prompt template for Question generation:
```python
SYSTEM_PROMPT: str = """
# Task
基于以下参考法律材料，生成至少{n}个法律问题。问题需要满足以下要求：

1. 复杂度要求：
- 问题的答案需要通过对参考法律材料的深入理解和分析才能得出
- 应该是一个开放性问题，需要进行推理和解释
- 不能是简单的是非题或事实性问题

2. 问题形式：
- 可以是案例分析题
- 可以是法律适用题
- 可以是法律概念解释题

3. 问题结构：
- 明确的问题陈述

4. 难度级别：
中等难度，适合法律专业学生或从业者思考和讨论


5. 输出格式：
请严格使用JSON格式输出，结构如下：
{{
  "questions": [
    {{
      "id": 1,
      "type": "案例分析/法律适用/概念解释...", 
      "question": "具体问题",
    }},
    {{
      "id": 2,
      ...
    }},
    {{
      "id": 3,
      ...
    }}
  ]
}}
"""

USER_PROMPT: str = """
# 参考法律材料
{prompt}

# 提示
生成的问题应该与提供的参考法律材料直接相关，但是必须假装参考法律材料对你不可见。
请以JSON格式输出：
"""
```

Here is our prompt template for Thought(COT) and Answer generation:
```python
SYSTEM_PROMPT: str = """你是一个专家级的AI助手，能够逐步解释推理过程。你将收到一个问题和相关参考资料。你的任务是重构并展示通向正确答案的完整推理路径。

对于每个推理步骤，提供一个标题，描述你在该步骤中所做的事情，以及内容。但必须展示至少三种不同的方法或途径来得出该答案。

要求：
1. 使用3-5个推理步骤
2. 探索多种方法以达到答案
3. 通过不同的方法验证给定答案
4. 考虑潜在的替代答案并解释为何被拒绝
5. 你必须假装没有参考资料，只可以把参考资料当作自己的知识
6. 考虑你可能是错的，如果你的推理是错的，它会在哪里
7. 充分测试所有其他可能性。你可能会错
8. 当你说你正在重新检查时，请真正重新检查，并使用另一种方法进行，不要只是说你正在重新检查

以JSON格式回应，包含以下键：
- 'title': 当前推理步骤的描述
- 'content': 该步骤的详细解释
- 'next_action': 'continue' 或 'final_answer'
有效的JSON响应示例：
[
  {{ 
      "title": "分析给定信息", 
      "content": "首先，让我们检查问题，以识别将指导我们解决过程的关键要素……", 
      "next_action": "continue"
  }},
  {{ 
      "title": "...", 
      "content": "...", 
      "next_action": "continue"
  }},
  ...
  {{ 
      "title": "...", 
      "content": "...", 
      "next_action": "final_answer"
  }}
]
"""

USER_PROMPT: str = """
# 问题：
{prompt}
# 参考资料：
{references}

请以JSON格式输出：
"""

```


## Training details

We use [Align-Anything](https://github.com/PKU-Alignment/align-anything) framework to conduct SFT training on [Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B). The training dataset and hyperparameters used are detailed below.

### Chat Template

Specifically, in SFT training, Q, T, and A in the [training dataset](https://huggingface.co/datasets/HKAIR-Lab/O1aw-sft-16k) are segmented by reserved tokens in the tokenizer of Llama-3.1-8B. For more details, see template:

```
system_prompt: str = ''
user_prompt: str = '<|reserved_special_token_0|>{input}<|reserved_special_token_1|>\n'
assistant_thinking: str = '<|reserved_special_token_2|>{thinking}<|reserved_special_token_3|>\n'
assistant_answer: str = '<|reserved_special_token_4|>{answer}<|reserved_special_token_5|>'
template = system_prompt + user_prompt + assistant_thinking + assistant_answer
```

### Hyperparameters

train_cfgs

    ```
    # The deepspeed configuration
    ds_cfgs: ds_z3_config.json
    # Number of training epochs
    epochs: 3
    # Seed for random number generator
    seed: 42
    # Batch size per device for training
    per_device_train_batch_size: 4
    # Batch size per device for evaluation
    per_device_eval_batch_size: 4
    # The number of gradient accumulation steps
    gradient_accumulation_steps: 16
    # Whether to use gradient checkpointing
    gradient_checkpointing: True
    # Initial learning rate
    learning_rate: 2.e-5
    # Type of learning rate scheduler
    lr_scheduler_type: cosine
    # Ratio of warmup steps for learning rate
    lr_warmup_ratio: 0.03
    # Weight decay coefficient
    weight_decay: 0.0
    # Hyper-parameters for adam optimizer
    adam_betas: [0.9, 0.95]
    # Hyper-parameters for adam epsilon
    adam_epsilon: 1.e-8
    # Enable bfloat 16 precision
    bf16: True
    # Enable float 16 precision
    fp16: False
    # The strategy of evaluation, choosing form [epoch, steps]
    eval_strategy: epoch
    # The evaluation interval in step-wise evaluation case
    eval_interval: 10
    # The max norm of gradient
    max_grad_norm: 1.0
    ```

data_cfgs

    ```
    # Datasets to use for training
    train_datasets: HKAIR-Lab/O1aw-sft-15k
    # The split of train datasets
    train_split: train
    ```

model_cfgs

    ```
    # Pretrained model name or path
    model_name_or_path: meta-llama/Llama-3.1-8B 
    # Whether to trust remote code
    trust_remote_code: True
    # The max token length
    model_max_length: 2048
    ```

For other hyperparameters, we use the default value in the [configure file](https://github.com/PKU-Alignment/align-anything/blob/main/align_anything/configs/train/text_to_text/sft.yaml). 

## Evaluation for HK Laws

In the planning, coming soon.


## Our teams
HK-O1aw is developed by the HKAIR research team, part of HKGAI. We specialize in developing reasoning techniques for large language models (LLMs). If you have any questions about HK-O1aw, feel free to reach out to us on the GitHub issue page.

## Citation
Please cite the repo if you use the data or code in this repo.

```bibtex
@misc{align_anything,
  author = {HKAIR Lab},
  title = {HK-O1aw Models: A HK Law Large Language Model using O1's Slow Thinking},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/HKAIR-Lab/HK-O1aw}},
}
```


## License

HK-O1aw models and datasets are released under Apache License 2.0.
